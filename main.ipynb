{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is this about\n",
    "\n",
    "This is an experimentation in implementing Gaussian Discriminant Analyis for prediction milti-class classifications.\n",
    "\n",
    "### Scope\n",
    "\n",
    "The target of this study is to test the capability of Gaussian Discriminant Analysis in predicting the weather using a pre-defined dataset found at https://www.kaggle.com/datasets/nikhil7280/weather-type-classification\n",
    "\n",
    "### Approach\n",
    "\n",
    "This study will makes use of the following techniques and formulaes after derivations done by the researcher\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$\n",
    "P(y=k|x) = \\frac{1}{\\sum_{i=0, i\\not= k}^kexp(-\\theta^T_ix + \\theta_{0i}) } \n",
    "$$\n",
    "\n",
    "where, when predicting for $k$ \n",
    "\n",
    "$\\theta_i = \\Sigma^-(\\mu_k - \\mu_i)$ and $\\theta_{0i} = ln\\frac{\\phi_i}{\\phi_k} + \\frac{1}{2}(\\mu_k^T\\Sigma^-\\mu_k - \\mu_i^T\\Sigma^-\\mu_i)$\n",
    "\n",
    "### Matrix shortcut for computing the parameters\n",
    "\n",
    "We can easily compute for the parameters using the following matrix multipications \n",
    "\n",
    "$$\n",
    "\\phi = \\frac{1}{n}\\sum_{i=1}^nY\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{X^TY}{\\sum_{i=1}^nY}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma = \\frac{1}{n}\\sum_{i = 1}^n(x^i - \\mu_{y^i})^T(x^i - \\mu_{y^i})\n",
    "$$\n",
    "\n",
    "Where \n",
    "\n",
    " $\\phi\\exists\\R^{1\\times K}$\n",
    "\n",
    " $\\mu\\exists\\R^{D \\times K}$ = where the $i'th$ column represents the mean for the $i'th$ classification\n",
    "\n",
    "$X\\exists\\R^{M \\times D}$ = where the $i'th$ row represents the $i'th$ training data\n",
    "\n",
    "$Y\\exists\\R^{M \\times K}$ = where the $i'th$ row represents the classification of the $i'th$ data represented in a                     one-hot row matrix\n",
    "\n",
    "Using this we can solve for the $\\theta_i$  and $\\theta_{0i}$ for every class $k$ and compose them in a matrix to be used below\n",
    "\n",
    "### Matrix Shortcut For Predictions in Multi-class\n",
    "\n",
    "To easily compute $P(y = k|x)$  for every $k$ what we can do is perform the following matrix transformations\n",
    "\n",
    "$$\n",
    "H(k) = sum(X'W)\n",
    "$$\n",
    "\n",
    "Where  \n",
    "\n",
    "$X'\\exists\\R^{M\\times D + 1}$ = Where the $i'th$ row corresponds with the $i'th$ dataset plus a bias for the intercept ( 1 )\n",
    "\n",
    "$W\\exists\\R^{D + 1\\times K}$ = Where the $i'th$ column represents the $\\theta_{i}$ for classification $k$ and the last row represents all the $\\theta_0$ where the $j'th$ column represents $\\theta_{0j}$\n",
    "\n",
    "$D$ = number of dimensions (features)\n",
    "\n",
    "$M$ = number of training data\n",
    "\n",
    "$K$  = number of classifications\n",
    "\n",
    "We then do this for every $k$ to produce a prediction for every k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAGE 1: DATA SANITATION AND COLLECTION\n",
    "\n",
    "First we will get the data (X and Y) and compose it to our intended format.\n",
    "\n",
    "We also have to take into account, and assign number for the categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\ron\\AppData\\Local\\Temp\\ipykernel_6724\\97523987.py:13: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  file_path = 'dataset\\weather_classification_data.csv'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot convert the series to <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [X, Y, y\u001b[38;5;241m.\u001b[39mvalues]\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# parse the data to X and Y\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m X, Y, y \u001b[38;5;241m=\u001b[39m \u001b[43mread_csv_to_XYy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdependent_variable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m X_T \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtranspose(X)\n\u001b[0;32m     50\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X)\n",
      "Cell \u001b[1;32mIn[48], line 38\u001b[0m, in \u001b[0;36mread_csv_to_XYy\u001b[1;34m(file_path, categorical_mapping, dependent_variable)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column, mapping \u001b[38;5;129;01min\u001b[39;00m categorical_mapping\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     36\u001b[0m     df[column] \u001b[38;5;241m=\u001b[39m df[column]\u001b[38;5;241m.\u001b[39mmap(mapping)\n\u001b[1;32m---> 38\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdependent_variable\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m [dependent_variable])\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# add a bias of 1 to take into account the intercept\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:248\u001b[0m, in \u001b[0;36m_coerce_method.<locals>.wrapper\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconverter\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on a single element Series is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will raise a TypeError in the future. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    245\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    246\u001b[0m     )\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot convert the series to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconverter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot convert the series to <class 'int'>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# assign numbers to the categorical values\n",
    "categorical_mapping = {\n",
    "    \"Weather Type\": {\"Rainy\": 0, \"Cloudy\": 1, \"Sunny\": 2, \"Snowy\": 3},\n",
    "    \"Cloud Cover\" : {\"overcast\": 0.,\"partly cloudy\": 1., \"clear\": 2., \"cloudy\": 3.},\n",
    "    \"Season\"     : {\"Spring\": 0., \"Autumn\": 1., \"Winter\": 2., \"Summer\": 3.},\n",
    "    \"Location\"    : {\"inland\": 0., \"mountain\": 1., \"coastal\": 2.}\n",
    "}\n",
    "\n",
    "# configs\n",
    "file_path = 'dataset\\weather_classification_data.csv'\n",
    "features = [\"Temperature\", \"Humidity\", \"Wind Speed\", \n",
    "            \"Precipitation (%)\", \"Cloud Cover\", \"Atmospheric Pressure\", \n",
    "            \"UV Index\", \"Season\", \"Visibility (km)\", \"Location\"]\n",
    "\n",
    "dependent_variable = \"Weather Type\"\n",
    "K = len(categorical_mapping[dependent_variable])\n",
    "D = len(features)\n",
    "M = None\n",
    "\n",
    "def display_tensor(tensor, name):\n",
    "    print(name + \": \\n\", tensor.numpy())\n",
    "\n",
    "def encode_row_matrix_to_one_hot(row_matrix, depth=K):\n",
    "    row_matrix = tf.reshape(row_matrix, [-1])\n",
    "    one_hot_matrix = tf.one_hot(row_matrix, depth=depth)\n",
    "    \n",
    "    return one_hot_matrix\n",
    "\n",
    "def read_csv_to_XYy(file_path, categorical_mapping, dependent_variable):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    for column, mapping in categorical_mapping.items():\n",
    "        df[column] = df[column].map(mapping)\n",
    "\n",
    "    y = df[dependent_variable]\n",
    "    x = df.drop(columns = [dependent_variable])\n",
    "\n",
    "    # add a bias of 1 to take into account the intercept\n",
    "    X = tf.concat([tf.convert_to_tensor(x.values, dtype=tf.float32), tf.ones([len(x), 1], dtype=tf.float32)], axis=1)\n",
    "    Y = encode_row_matrix_to_one_hot(tf.convert_to_tensor(y.values, dtype=tf.uint8))\n",
    "\n",
    "    return [X, Y, y.values]\n",
    "\n",
    "# parse the data to X and Y\n",
    "X, Y, y = read_csv_to_XYy(file_path, categorical_mapping, dependent_variable)\n",
    "X_T = tf.transpose(X)\n",
    "M = len(X)\n",
    "\n",
    "display_tensor(X, \"X\")\n",
    "display_tensor(Y, \"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAGE 2: COMPUTE FOR THE PARAMTERS\n",
    "We then compute for our intended parameters which are $\\phi, \\Sigma, \\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. ... 1. 3. 0.]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y)\n\u001b[1;32m----> 9\u001b[0m     diff \u001b[38;5;241m=\u001b[39m X_T[:, i] \u001b[38;5;241m-\u001b[39m \u001b[43mMU\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     10\u001b[0m     SIGMA \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(tf\u001b[38;5;241m.\u001b[39mtranspose(diff), diff) \u001b[38;5;241m/\u001b[39m M\n\u001b[0;32m     13\u001b[0m display_tensor(PHI, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPHI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\ops\\tensor_getitem_override.py:62\u001b[0m, in \u001b[0;36m_check_index\u001b[1;34m(idx)\u001b[0m\n\u001b[0;32m     57\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _SUPPORTED_SLICE_DTYPES \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     idx\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     60\u001b[0m   \u001b[38;5;66;03m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[39;00m\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;66;03m# will break `_slice_helper` contract.\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(_SLICE_TYPE_ERROR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx))\n",
      "\u001b[1;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 0.0"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_SUM = tf.reduce_sum(Y, axis=0)\n",
    "PHI = Y_SUM / M\n",
    "MU  = tf.matmul(X_T, Y) / Y_SUM\n",
    "SIGMA = tf.Variable(initial_value=tf.zeros(shape=(K, K)), dtype=tf.float32)\n",
    "\n",
    "# Sigma\n",
    "for i in range(K):\n",
    "    diff = X_T[:, i] - MU[:, y[i]]\n",
    "    SIGMA += tf.matmul(tf.transpose(diff), diff) / M\n",
    "\n",
    "\n",
    "display_tensor(PHI, \"PHI\")\n",
    "display_tensor(MU, \"MU\")\n",
    "display_tensor(SIGMA, \"SIGMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
